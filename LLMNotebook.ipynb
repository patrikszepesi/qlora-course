{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db4b062-be07-426f-9706-8078fb755e68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T13:33:34.544289Z",
     "iopub.status.busy": "2025-06-21T13:33:34.544002Z",
     "iopub.status.idle": "2025-06-21T13:33:36.624681Z",
     "shell.execute_reply": "2025-06-21T13:33:36.623857Z",
     "shell.execute_reply.started": "2025-06-21T13:33:34.544258Z"
    }
   },
   "outputs": [],
   "source": [
    "%pip install --quiet --upgrade transformers datasets sagemaker s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4971a12-3aa7-420e-b724-b7fc88ab58e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T13:33:36.625981Z",
     "iopub.status.busy": "2025-06-21T13:33:36.625375Z",
     "iopub.status.idle": "2025-06-21T13:33:38.806362Z",
     "shell.execute_reply": "2025-06-21T13:33:38.805689Z",
     "shell.execute_reply.started": "2025-06-21T13:33:36.625955Z"
    }
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cf5f3b-7b05-406c-8748-53e4145d63a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T13:33:38.807850Z",
     "iopub.status.busy": "2025-06-21T13:33:38.807543Z",
     "iopub.status.idle": "2025-06-21T13:33:38.965397Z",
     "shell.execute_reply": "2025-06-21T13:33:38.964635Z",
     "shell.execute_reply.started": "2025-06-21T13:33:38.807821Z"
    }
   },
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "sess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef30942-0e51-40f7-9179-635b943fbe43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T13:33:38.970643Z",
     "iopub.status.busy": "2025-06-21T13:33:38.970225Z",
     "iopub.status.idle": "2025-06-21T13:33:39.123785Z",
     "shell.execute_reply": "2025-06-21T13:33:39.123123Z",
     "shell.execute_reply.started": "2025-06-21T13:33:38.970617Z"
    }
   },
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aefd394-0c21-4999-b973-8cfdf76e447e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T13:33:39.125320Z",
     "iopub.status.busy": "2025-06-21T13:33:39.124996Z",
     "iopub.status.idle": "2025-06-21T13:33:39.131049Z",
     "shell.execute_reply": "2025-06-21T13:33:39.130379Z",
     "shell.execute_reply.started": "2025-06-21T13:33:39.125293Z"
    }
   },
   "outputs": [],
   "source": [
    "sess.boto_region_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d09c0df-3d93-4c12-af5e-2b2ca2a8c0d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T13:33:39.132553Z",
     "iopub.status.busy": "2025-06-21T13:33:39.132202Z",
     "iopub.status.idle": "2025-06-21T13:33:41.496126Z",
     "shell.execute_reply": "2025-06-21T13:33:41.495368Z",
     "shell.execute_reply.started": "2025-06-21T13:33:39.132524Z"
    }
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from random import randrange\n",
    "\n",
    "dataset = load_dataset(\"databricks/databricks-dolly-15k\", split = \"train\")\n",
    "\n",
    "print(f\"dataset size: {len(dataset)}\")\n",
    "print(dataset[randrange(len(dataset))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0386d9-3b0c-42b0-a281-97eda2d7268f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T13:33:41.497587Z",
     "iopub.status.busy": "2025-06-21T13:33:41.497076Z",
     "iopub.status.idle": "2025-06-21T13:33:41.502098Z",
     "shell.execute_reply": "2025-06-21T13:33:41.501428Z",
     "shell.execute_reply.started": "2025-06-21T13:33:41.497554Z"
    }
   },
   "outputs": [],
   "source": [
    "def format_dolly(sample):\n",
    "    instruction = f\"### Instruction\\n{sample['instruction']}\"\n",
    "    context = f\"### Context\\n{sample['context']}\" if len(sample['context']) > 0 else None\n",
    "    response = f\"### Answer\\n{sample['response']}\"\n",
    "    prompt = \"\\n\\n\".join([i for i in [instruction,context,response] if i is not None ])\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70ad778-0bc5-4e8c-8aed-5d79163a62c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T13:33:41.503035Z",
     "iopub.status.busy": "2025-06-21T13:33:41.502766Z",
     "iopub.status.idle": "2025-06-21T13:33:41.509689Z",
     "shell.execute_reply": "2025-06-21T13:33:41.508951Z",
     "shell.execute_reply.started": "2025-06-21T13:33:41.503014Z"
    }
   },
   "outputs": [],
   "source": [
    "print(format_dolly(dataset[randrange(len(dataset))]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8968c3d5-dd0d-4a4a-ab37-1e056594f102",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T13:33:41.510817Z",
     "iopub.status.busy": "2025-06-21T13:33:41.510528Z",
     "iopub.status.idle": "2025-06-21T13:33:41.514232Z",
     "shell.execute_reply": "2025-06-21T13:33:41.513507Z",
     "shell.execute_reply.started": "2025-06-21T13:33:41.510789Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"HF_TOKEN\"] = \"<INSERT YOUR OWN TOKEN>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710185e6-416f-4c91-84f5-b63338fe0fd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T13:33:41.515723Z",
     "iopub.status.busy": "2025-06-21T13:33:41.515179Z",
     "iopub.status.idle": "2025-06-21T13:33:46.167026Z",
     "shell.execute_reply": "2025-06-21T13:33:46.166306Z",
     "shell.execute_reply.started": "2025-06-21T13:33:41.515695Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_id = \"mistralai/Mixtral-8x7B-v0.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfbc091-e742-4c27-9a48-c85fc762eba4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T13:33:46.168723Z",
     "iopub.status.busy": "2025-06-21T13:33:46.167967Z",
     "iopub.status.idle": "2025-06-21T13:33:46.173695Z",
     "shell.execute_reply": "2025-06-21T13:33:46.173056Z",
     "shell.execute_reply.started": "2025-06-21T13:33:46.168690Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c25373-bafe-48bd-88ff-b11ce1bc6b73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T13:33:46.175445Z",
     "iopub.status.busy": "2025-06-21T13:33:46.174782Z",
     "iopub.status.idle": "2025-06-21T13:33:46.319488Z",
     "shell.execute_reply": "2025-06-21T13:33:46.318597Z",
     "shell.execute_reply.started": "2025-06-21T13:33:46.175416Z"
    }
   },
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from itertools import chain\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "def template_dataset(sample):\n",
    "    sample['text'] = f\"{format_dolly(sample)}{tokenizer.eos_token}\"\n",
    "    return sample\n",
    "\n",
    "dataset = dataset.map(template_dataset,remove_columns=list(dataset.features))\n",
    "\n",
    "#print(dataset[randint(0,len(dataset))]['text'])\n",
    "\n",
    "remainder = {'input_ids':[],'attention_mask':[],'token_type_ids':[]}\n",
    "\n",
    "def chunk(sample, chunk_length = 2048):\n",
    "\n",
    "    global remainder\n",
    "\n",
    "    concatenated_examples = {k: list(chain(*sample[k])) for k in sample.keys()}\n",
    "\n",
    "    concatenated_examples = {\n",
    "        k: remainder[k] + concatenated_examples[k] for k in concatenated_examples.keys()\n",
    "    }\n",
    "\n",
    "    batch_total_length = len(concatenated_examples[list(sample.keys())[0]])\n",
    "\n",
    "    if batch_total_length >= chunk_length:\n",
    "        batch_total_length = (batch_total_length // chunk_length) * chunk_length\n",
    "        \n",
    "    result = {\n",
    "        k: [t[i: i + chunk_length] for i in range(0, batch_total_length, chunk_length)] for k,t in concatenated_examples.items()\n",
    "    }\n",
    "    \n",
    "    remainder = {\n",
    "        k: concatenated_examples[k][batch_total_length:] for k in concatenated_examples.keys()\n",
    "    }\n",
    "\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result\n",
    "\n",
    "lm_dataset = dataset.map(\n",
    "    lambda sample: tokenizer(sample[\"text\"]),\n",
    "    batched = True,\n",
    "    remove_columns = list(dataset.features)\n",
    ").map(\n",
    "    partial(chunk,chunk_length=2048),\n",
    "    batched = True\n",
    ")\n",
    "\n",
    "print(f\"Total number of samples: {len(lm_dataset)}\") # you have this many chunks, and each is 2048 tokens long\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a67a751-3dab-43a5-a024-cda442041826",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T13:33:46.323720Z",
     "iopub.status.busy": "2025-06-21T13:33:46.323497Z",
     "iopub.status.idle": "2025-06-21T13:33:46.329926Z",
     "shell.execute_reply": "2025-06-21T13:33:46.329124Z",
     "shell.execute_reply.started": "2025-06-21T13:33:46.323701Z"
    }
   },
   "outputs": [],
   "source": [
    "207655-206848 # 807 tokens from the first batch that will be put into the remainder dictirionary,\n",
    "#and that will be processed with tht next batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04ad697",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import s3fs\n",
    "\n",
    "training_input_path = f\"s3://<YOUR_BUCKET_NAME>/processed/mixtral/dolly/train\"\n",
    "\n",
    "lm_dataset.save_to_disk(training_input_path)\n",
    "print(\"uploading the dataset to s3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a9395e-8a39-4a2c-8391-a43621505b06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-21T14:09:05.992486Z",
     "iopub.status.busy": "2025-06-21T14:09:05.991726Z",
     "iopub.status.idle": "2025-06-21T14:09:06.239538Z",
     "shell.execute_reply": "2025-06-21T14:09:06.238574Z",
     "shell.execute_reply.started": "2025-06-21T14:09:05.992453Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "\n",
    "job_name = f\"mixtral-8x7b-qlora-{time.strftime('%Y-%m-%d-%H-%M-%S', time.localtime())}\"\n",
    "\n",
    "hyperparameters = {\n",
    "    \"model_id\": model_id,\n",
    "    \"dataset_path\": \"/opt/ml/input/data/training\",\n",
    "    \"epochs\": 2,\n",
    "    \"per_device_train_batch_size\": 2,\n",
    "    \"lr\": 2e-4,\n",
    "    \"merge_weights\": True,\n",
    "}\n",
    "\n",
    "huggingface_estimator = HuggingFace(\n",
    "    entry_point = \"run_clm.py\",\n",
    "    source_dir= \"scripts\",\n",
    "    instance_type = \"ml.g5.24xlarge\",\n",
    "    instance_count = 1,\n",
    "    base_job_name = job_name,\n",
    "    role = role,\n",
    "    volume_size = 300,\n",
    "    transformers_version= \"4.28\",\n",
    "    pytorch_version= \"2.0\",\n",
    "    py_version= \"py310\",\n",
    "    hyperparameters = hyperparameters,\n",
    "    environment = {\n",
    "        \"HUGGINFACE_HUB_CACHE\": \"/tmp/.cache\"\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166b707c-9c4e-448e-aedc-c6fbf7cb183e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"training\": training_input_path}\n",
    "huggingface_estimator.fit(data,wait = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
